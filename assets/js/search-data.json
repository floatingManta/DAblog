{
  
    
        "post0": {
            "title": "로그파일 분석하기",
            "content": "!pip3 install pandas_profiling --upgrade . Requirement already satisfied: pandas_profiling in /usr/local/lib/python3.7/dist-packages (1.4.1) Collecting pandas_profiling Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB) |████████████████████████████████| 262 kB 5.2 MB/s Requirement already satisfied: matplotlib&gt;=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (3.2.2) Collecting pydantic&gt;=1.8.1 Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB) |████████████████████████████████| 10.9 MB 48.5 MB/s Requirement already satisfied: missingno&gt;=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (0.5.1) Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,&gt;=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.3.5) Collecting tangled-up-in-unicode==0.2.0 Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB) |████████████████████████████████| 4.7 MB 25.9 MB/s Requirement already satisfied: tqdm&gt;=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (4.64.0) Collecting phik&gt;=0.11.1 Downloading phik-0.12.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (690 kB) |████████████████████████████████| 690 kB 53.5 MB/s Requirement already satisfied: scipy&gt;=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.4.1) Requirement already satisfied: joblib~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.1.0) Collecting PyYAML&gt;=5.0.0 Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB) |████████████████████████████████| 596 kB 55.9 MB/s Collecting requests&gt;=2.24.0 Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB) |████████████████████████████████| 63 kB 1.7 MB/s Requirement already satisfied: seaborn&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (0.11.2) Collecting multimethod&gt;=1.4 Downloading multimethod-1.8-py3-none-any.whl (9.8 kB) Collecting visions[type_image_path]==0.7.4 Downloading visions-0.7.4-py3-none-any.whl (102 kB) |████████████████████████████████| 102 kB 11.9 MB/s Collecting htmlmin&gt;=0.1.12 Downloading htmlmin-0.1.12.tar.gz (19 kB) Requirement already satisfied: jinja2&gt;=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (2.11.3) Collecting markupsafe~=2.1.1 Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB) Requirement already satisfied: numpy&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pandas_profiling) (1.21.6) Requirement already satisfied: attrs&gt;=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4-&gt;pandas_profiling) (21.4.0) Requirement already satisfied: networkx&gt;=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4-&gt;pandas_profiling) (2.6.3) Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4-&gt;pandas_profiling) (7.1.2) Collecting imagehash Downloading ImageHash-4.2.1.tar.gz (812 kB) |████████████████████████████████| 812 kB 50.8 MB/s Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas_profiling) (0.11.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas_profiling) (3.0.8) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas_profiling) (2.8.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.2.0-&gt;pandas_profiling) (1.4.2) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib&gt;=3.2.0-&gt;pandas_profiling) (4.2.0) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,&gt;=0.25.3-&gt;pandas_profiling) (2022.1) Collecting scipy&gt;=1.4.1 Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB) |████████████████████████████████| 38.1 MB 1.1 MB/s Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib&gt;=3.2.0-&gt;pandas_profiling) (1.15.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas_profiling) (2021.10.8) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas_profiling) (2.10) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas_profiling) (1.24.3) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.24.0-&gt;pandas_profiling) (2.0.12) Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash-&gt;visions[type_image_path]==0.7.4-&gt;pandas_profiling) (1.3.0) Building wheels for collected packages: htmlmin, imagehash Building wheel for htmlmin (setup.py) ... done Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=5a1c0b2d5766cc3939d187379ab89e9fdca08e5f1f0f1896bf84b1bb4caa5d29 Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655 Building wheel for imagehash (setup.py) ... done Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=9c69ba0d5c5d76d7add774dd24d0fc7167d493995d6b79e407ddc9c71cc1742e Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e Successfully built htmlmin imagehash Installing collected packages: tangled-up-in-unicode, scipy, multimethod, visions, markupsafe, imagehash, requests, PyYAML, pydantic, phik, htmlmin, pandas-profiling Attempting uninstall: scipy Found existing installation: scipy 1.4.1 Uninstalling scipy-1.4.1: Successfully uninstalled scipy-1.4.1 Attempting uninstall: markupsafe Found existing installation: MarkupSafe 2.0.1 Uninstalling MarkupSafe-2.0.1: Successfully uninstalled MarkupSafe-2.0.1 Attempting uninstall: requests Found existing installation: requests 2.23.0 Uninstalling requests-2.23.0: Successfully uninstalled requests-2.23.0 Attempting uninstall: PyYAML Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 Attempting uninstall: pandas-profiling Found existing installation: pandas-profiling 1.4.1 Uninstalling pandas-profiling-1.4.1: Successfully uninstalled pandas-profiling-1.4.1 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible. Successfully installed PyYAML-6.0 htmlmin-0.1.12 imagehash-4.2.1 markupsafe-2.1.1 multimethod-1.8 pandas-profiling-3.2.0 phik-0.12.2 pydantic-1.9.0 requests-2.27.1 scipy-1.7.3 tangled-up-in-unicode-0.2.0 visions-0.7.4 . pip install MarkupSafe==2.0.1 . Collecting MarkupSafe==2.0.1 Downloading MarkupSafe-2.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (31 kB) Installing collected packages: MarkupSafe Attempting uninstall: MarkupSafe Found existing installation: MarkupSafe 2.1.1 Uninstalling MarkupSafe-2.1.1: Successfully uninstalled MarkupSafe-2.1.1 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pandas-profiling 3.2.0 requires markupsafe~=2.1.1, but you have markupsafe 2.0.1 which is incompatible. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. Successfully installed MarkupSafe-2.0.1 . import pandas as pd from tqdm.notebook import tqdm import pandas_profiling . log_date_df = pd.read_csv(&#39;filesdataframe.csv&#39;) . with open(&#39;files.txt&#39;, &#39;r&#39;, encoding=&#39;utf-8&#39;) as f: lines = f.read().splitlines() f.close() . lines[:10] # 보안상 출력 삭제 . log_date_df = pd.DataFrame([line.split(&#39; &#39;) for line in lines[4:]], columns = lines[3].split(&#39; &#39;)[1:]) . log_date_df.to_csv(&#39;filesdataframe.csv&#39;) . pr = log_date_df.profile_report() pr # 보안상 출력 삭제 . Appendix . for line in tqdm(lines[4:]): # print(line.split(&#39; t&#39;)) # print(len(line.split(&#39; t&#39;))) # users_log_raw = pd.concat([users_log_raw, pd.Series(line.split(&#39; &#39;))], axis=1) # users_log_raw = users_log_raw.append(pd.DataFrame([line.split(&#39; &#39;)])) [line.split(&#39; &#39;)] . KeyboardInterrupt Traceback (most recent call last) &lt;ipython-input-32-6555b2ec1e83&gt; in &lt;module&gt;() 3 # print(len(line.split(&#39; t&#39;))) 4 # users_log_raw = pd.concat([users_log_raw, pd.Series(line.split(&#39; &#39;))], axis=1) -&gt; 5 users_log_raw = users_log_raw.append(pd.DataFrame([line.split(&#39; &#39;)])) /usr/local/lib/python3.7/dist-packages/pandas/core/frame.py in append(self, other, ignore_index, verify_integrity, sort) 8967 ignore_index=ignore_index, 8968 verify_integrity=verify_integrity, -&gt; 8969 sort=sort, 8970 ) 8971 ).__finalize__(self, method=&#34;append&#34;) /usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --&gt; 311 return func(*args, **kwargs) 312 313 return wrapper /usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py in concat(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy) 305 ) 306 --&gt; 307 return op.get_result() 308 309 /usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py in get_result(self) 531 532 new_data = concatenate_managers( --&gt; 533 mgrs_indexers, self.new_axes, concat_axis=self.bm_axis, copy=self.copy 534 ) 535 if not self.copy: /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in concatenate_managers(mgrs_indexers, axes, concat_axis, copy) 224 fastpath = blk.values.dtype == values.dtype 225 else: --&gt; 226 values = _concatenate_join_units(join_units, concat_axis, copy=copy) 227 fastpath = False 228 /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in _concatenate_join_units(join_units, concat_axis, copy) 490 to_concat = [ 491 ju.get_reindexed_values(empty_dtype=empty_dtype, upcasted_na=upcasted_na) --&gt; 492 for ju in join_units 493 ] 494 /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in &lt;listcomp&gt;(.0) 490 to_concat = [ 491 ju.get_reindexed_values(empty_dtype=empty_dtype, upcasted_na=upcasted_na) --&gt; 492 for ju in join_units 493 ] 494 /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in get_reindexed_values(self, empty_dtype, upcasted_na) 409 fill_value = upcasted_na 410 --&gt; 411 if self.is_valid_na_for(empty_dtype): 412 blk_dtype = getattr(self.block, &#34;dtype&#34;, None) 413 /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in is_valid_na_for(self, dtype) 368 if self.dtype == object: 369 values = self.block.values --&gt; 370 return all(is_valid_na_for_dtype(x, dtype) for x in values.ravel(order=&#34;K&#34;)) 371 372 if self.dtype.kind == dtype.kind == &#34;M&#34; and not is_dtype_equal( /usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py in &lt;genexpr&gt;(.0) 368 if self.dtype == object: 369 values = self.block.values --&gt; 370 return all(is_valid_na_for_dtype(x, dtype) for x in values.ravel(order=&#34;K&#34;)) 371 372 if self.dtype.kind == dtype.kind == &#34;M&#34; and not is_dtype_equal( /usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/missing.py in is_valid_na_for_dtype(obj, dtype) 627 elif dtype.kind == &#34;m&#34;: 628 return not isinstance(obj, (np.datetime64, Decimal)) --&gt; 629 elif dtype.kind in [&#34;i&#34;, &#34;u&#34;, &#34;f&#34;, &#34;c&#34;]: 630 # Numeric 631 return obj is not NaT and not isinstance(obj, (np.datetime64, np.timedelta64)) KeyboardInterrupt: . pr = pandas_profiling.ProfileReport(log_date_df) pr . TypeError Traceback (most recent call last) &lt;ipython-input-52-2b9be7b84bf2&gt; in &lt;module&gt;() -&gt; 1 pr = pandas_profiling.ProfileReport(log210817) 2 pr /usr/local/lib/python3.7/dist-packages/pandas_profiling/__init__.py in __init__(self, df, **kwargs) 64 sample = kwargs.get(&#39;sample&#39;, df.head()) 65 &gt; 66 description_set = describe(df, **kwargs) 67 68 self.html = to_html(sample, /usr/local/lib/python3.7/dist-packages/pandas_profiling/describe.py in describe(df, bins, check_correlation, correlation_threshold, correlation_overrides, check_recoded, pool_size, **kwargs) 390 if name not in names: 391 names.append(name) --&gt; 392 variable_stats = pd.concat(ldesc, join_axes=pd.Index([names]), axis=1) 393 variable_stats.columns.names = df.columns.names 394 /usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --&gt; 311 return func(*args, **kwargs) 312 313 return wrapper TypeError: concat() got an unexpected keyword argument &#39;join_axes&#39; . users_log_raw # 보안상 출력 삭제 . !pip freeze |grep pandas-profiling . pandas-profiling==1.4.1 . file = open(&#39;files.log&#39;, &#39;r&#39;) . # with open(&#39;files.log&#39;, &#39;r&#39;, encoding=&#39;utf-16&#39;) as f: UTF-16 stream does not start with BOM # with open(&#39;files.log&#39;, &#39;r&#39;, encoding=enc) as f: &#39;charmap&#39; codec can&#39;t decode byte 0x90 in position 5926451: character maps to &lt;undefined&gt; with open(&#39;files.log&#39;, &#39;r&#39;, encoding=enc) as f: # lines = f.readline() lines = f.read().splitlines() f.close() . UnicodeDecodeError Traceback (most recent call last) &lt;ipython-input-44-1a4b33beda3e&gt; in &lt;module&gt;() 3 with open(&#39;ex210817.log&#39;, &#39;r&#39;, encoding=enc) as f: 4 # lines = f.readline() -&gt; 5 lines = f.read().splitlines() 6 f.close() /usr/lib/python3.7/encodings/cp1254.py in decode(self, input, final) 21 class IncrementalDecoder(codecs.IncrementalDecoder): 22 def decode(self, input, final=False): &gt; 23 return codecs.charmap_decode(input,self.errors,decoding_table)[0] 24 25 class StreamWriter(Codec,codecs.StreamWriter): UnicodeDecodeError: &#39;charmap&#39; codec can&#39;t decode byte 0x90 in position 5926451: character maps to &lt;undefined&gt; . lines = file.read().splitlines() file.close() #pandas profiling 업데이트하고 런타임 재시작하니 갑자기 &#39;utf-8&#39; codec can&#39;t decode byte 0xbc in position 52441641: invalid start byte . UnicodeDecodeError Traceback (most recent call last) &lt;ipython-input-7-f70f446e44ad&gt; in &lt;module&gt;() -&gt; 1 lines = file.read().splitlines() 2 file.close() 3 #pandas profiling 업데이트하고 런타임 재시작하니 갑자기 &#39;utf-8&#39; codec can&#39;t decode byte 0xbc in position 52441641: invalid start byte /usr/lib/python3.7/codecs.py in decode(self, input, final) 320 # decode input (taking the buffer into account) 321 data = self.buffer + input --&gt; 322 (result, consumed) = self._buffer_decode(data, self.errors, final) 323 # keep undecoded input until the next call 324 self.buffer = data[consumed:] UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xbc in position 52441641: invalid start byte . lines[3].decode() . &#39;#Fields: date time cs-method cs-uri-stem cs-uri-query cs-username c-ip cs(User-Agent) cs(Referer) sc-status sc-substatus sc-win32-status sc-bytes cs-bytes time-taken&#39; . users_log_raw = pd.DataFrame(columns = lines[3].decode().split(&#39; &#39;)[1:]) . log_date_df = pd.DataFrame([line.decode().split(&#39; &#39;) for line in lines[4:]], columns = lines[3].decode().split(&#39; &#39;)[1:]) . UnicodeDecodeError Traceback (most recent call last) &lt;ipython-input-25-e98b3610b861&gt; in &lt;module&gt;() -&gt; 1 log210817 = pd.DataFrame([line.decode().split(&#39; &#39;) for line in lines[4:]], columns = lines[3].decode().split(&#39; &#39;)[1:]) &lt;ipython-input-25-e98b3610b861&gt; in &lt;listcomp&gt;(.0) -&gt; 1 log210817 = pd.DataFrame([line.decode().split(&#39; &#39;) for line in lines[4:]], columns = lines[3].decode().split(&#39; &#39;)[1:]) UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xbc in position 31: invalid start byte . lines[148636].decode().split(&#39; &#39;) . UnicodeDecodeError Traceback (most recent call last) &lt;ipython-input-28-d784f97e443f&gt; in &lt;module&gt;() -&gt; 1 lines[148636].decode().split(&#39; &#39;) UnicodeDecodeError: &#39;utf-8&#39; codec can&#39;t decode byte 0xbc in position 31: invalid start byte . for line in tqdm(lines[4:]): print(line.decode().split(&#39; &#39;)) # 어느 행에서 오류 발생하는지 확인 . lines[148636] # 내용: 한국어 포함 jpg 파일 . IndexError Traceback (most recent call last) &lt;ipython-input-37-ec5c5841f2f9&gt; in &lt;module&gt;() -&gt; 1 lines[148636] # 내용: /Media/서울대_우연철_287_164(1).jpg IndexError: string index out of range . import chardet . rawdata = open(&#39;files.log&#39;, &#39;rb&#39;).read() result = chardet.detect(rawdata) enc = result[&#39;encoding&#39;] . enc . &#39;Windows-1254&#39; .",
            "url": "https://floatingmanta.github.io/DAblog/2022/05/15/read-log-file.html",
            "relUrl": "/2022/05/15/read-log-file.html",
            "date": " • May 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "[Python]가상환경 패키지 업데이트",
            "content": "` import pkg_resources from subprocess import call . for dist in pkg_resources.working_set: call(“python -m pip install –upgrade “ + dist.project_name, shell=True) ` .",
            "url": "https://floatingmanta.github.io/DAblog/markdown/2022/05/01/Update-All-Package.html",
            "relUrl": "/markdown/2022/05/01/Update-All-Package.html",
            "date": " • May 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "VSCode 확장 이전 버전 VSIX 파일 다운로드 받기",
            "content": "Visual Studio Code Extension의 이전 버전 VSIX파일 다운로드 . 목적 . VSCode의 확장을 오프라인으로 설치하려면, 스토어에서 VSIX파일을 다운받아야 한다. 이전 버전을 설치하려면, VSCode에서 확장을 오른클릭하여 나오는 다른 버전 설치하기를 누른다. . 그런데 이전 버전을 오프라인 설치하려면? 스토어의 다운로드 기능은 항상 최신 버전 VSIX만 제공한다. . 해결 . https://stackoverflow.com/questions/69398500/vscode-download-older-version-of-an-extension 관련 stackoverflow 글 . https://www.vsixhub.com/ vsix 이전 버전 보관 사이트 . 상세 상황 . Offline환경에서 VSCode의 IntelliSense가 작동하지 않는다. Setting.json을 수정하여 언어를 pylance로 바꾸고 ExtraPaths는 이미 추가해 본 상황 최후의 수단으로 Jupyter 확장을 업데이트 시도 그런데 다운받은 VSIX가 VSCode 1.66.1과 호환되지 않는다는 에러 발생 그럼 설치 가능한 이전 버전을 찾아야하기 때문에 본 문서의 해결책 탐색 .",
            "url": "https://floatingmanta.github.io/DAblog/markdown/2022/04/17/Previous-Version-VSIX.html",
            "relUrl": "/markdown/2022/04/17/Previous-Version-VSIX.html",
            "date": " • Apr 17, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "시행착오 일기",
            "content": "시행착오 . vscode에서 주피터 노트북 IntelliSence켜기 https://www.programmersought.net/article/344759916.html | https://linuxtut.com/en/92aa7a02b89edad63a8f/ 지금까지 둘 다 실패 | | . → Jupyter Extension 업데이트로 해결 . C++ 14 이상 다운로드 받기 https://pivox.tistory.com/35 + https://pivox.tistory.com/34 | https://cofs.tistory.com/388 | https://www.microsoft.com/en-in/download/confirmation.aspx?id=48159 15 업데이트 3판+재배포판 다운로드 받아서 내부망에서 실행하기: 여전히 설치 패키지가 없거나 손상되었다고 함 cmd로 visualcppbuildtools_full.exe /layout C: VisualStudio2015_packages 실행해서 파일 다운로드 받기: 여전히 설치 패키지가 없거나 손상되었다고 함 | 성과: 탐색기에서 cmd 실행하기 | . | .",
            "url": "https://floatingmanta.github.io/DAblog/markdown/2022/04/16/trial-and-error.html",
            "relUrl": "/markdown/2022/04/16/trial-and-error.html",
            "date": " • Apr 16, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "[Python]오프라인에서 가상환경 설정하기",
            "content": "Python 가상환경 설정 . 조건: . 인터넷 연결이 없는 오프라인 | Windows 10환경 | Visual Studio Code사용 | Jupyter Notebook을 가상환경 커널에 연결 | . 목적 . AS-IS: 기존 파이썬 환경은 콘다 기반이고 3.7버전임 콘다 기반이어서 콘다 유료화 이슈 이후 직장에서 가상환경을 운영하기 불리함 | 매 업데이트마다 콘다 오프라인 설치 파일을 내부망으로 옮겨줘야 함 | . | 가상환경을 운영하는 이유 글로벌 환경에서 파이썬 및 패키지 충돌로 인해 환경이 깨지는 상황을 방지함 | . | TO-DO: 2022년 4월 15일 기준 파이썬 3.10.4 버전으로 콘다가 아닌 가상환경을 생성하고 패키지를 설치하여 운영함 | . 작업 . 1. 파이썬을 설치한다. 2. 가상환경을 생성한다. 3. 인터넷 연결 환경에서 패키지를 설치하고 requirements.txt를 생성하고 패키지를 다운로드한다. 4. 내부망으로 패키지를 옮겨 설치한다. . 1. 파이썬을 설치한다. . 고민사항: . 여러 버전의 Python을 설치하면 정상적으로 작동할까? | 기존 콘다 배포판을 지우지 않은 상태에서 바닐라 Python을 설치하면 정상적으로 작동할까? | . https://www.python.org 에 접속하여 Windows용 원하는 버전 설치파일을 다운로드 받는다. | 내부망과 외부망 PC에 각각 설치한다. 기존에 있던 버전이라면 설치파일 실행 시 업데이트를 선택할 수 있고, 다른 버전이라면 설치를 선택할 수 있다. 설치 시 PATH에 추가하는 옵션을 선택하고 설치 위치를 최대한 사용자 바로 아래에 간단하게 설치할 수 있도록 한다. | cmd를 열고 다음 코드로 가상환경 설치를 원하는 디렉토리에 실행파일을 복사한다. copy python310 python.exe python310 python310.exe | 2. 가상환경을 만든다. . 고민사항: . 콘다 가상환경과 파이썬 가상환경이 같이 운영될까? | VSCode에 어떻게 인식시킬까? | . VSCode를 켜고 터미널을 연다. VSCode로 가상환경을 연결하려면 반드시 VSCode에서 실행해야 한다. | 가상환경을 만들고 싶은 위치로 이동한다. cd 가상환경을 만들 위치 | 다음 코드를 실행한다. py -3 -m venv (가상환경 이름) (가상환경 이름) scripts activate . 만일 “Activate.ps1 is not digitally signed. You cannot run this script on the current system.”라고 뜨면서 실행이 안되는 경우, Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process을 실행한다. 그 후 다시 위의 activate 명령을 실행한다. . | 파이썬 설치와 가상환경 생성은 내부망과 외부망 모두에서 진행한다. . 3. 패키지를 설치한다. . 고민사항: . 어떻게 빠르게 각종 필요한 패키지를 설치할 수 있을까? | 파이썬 버전에 따라 패키지 설치 파일이 다른데 어떻게 내 외부망에서 일치시킬 수 있을까?: 이 문제는 위의 1,2 단계에서 내외부에 전부 같은 단계를 실행하여 방지한다. 이 과정을 무시하여 발생할 수 있는 문제는 다음 페이지 참고: https://cryptosalamander.tistory.com/148 판다스 에러난 경우 | 패키지 중 MicroSoft C++ 14.0이 먼저 필요한 경우 어떻게 설치해야 할까? | . 기존 가상환경을 activate한 터미널에서 다음 명령을 실행하여 requirments.txt를 만든다. pip freeze &gt; requirements.txt | 외부망으로 requirements.txt를 옮기고 최신 Python 버전 가상환경 터미널에서 다음 명령을 실행하여 패키지를 다운로드 받는다. pip download $PATH -r . requirements.txt requirements파일의 위치를 지정해 줄 수도 있고, 파일을 가상환경이 활성화된 위치로 이동하여 바로 명령이 실행되게 할 수도 있다. 웬만하면 다운로드 위치를 지정해서 폴더 통째로 압축이 편하도록 해 준다. | 다운받은 패키지를 압축해서 내부망으로 옮긴다. | VSCode 터미널에서 다음 명령어를 실행하여 패키지를 설치한다. pip install --no-index --find-links=&quot;./&quot; -r . requirements.txt | MicroSoft C++ 14.0 이상을 요구하는 경우, Bulid Tool을 설치한다. Visual Studio 다운로드 페이지에서 Visual Studio용 도구 부분을 클릭한다. 늘어난 목록 중 Visual Studio 2022용 빌드 도구를 다운로드 받는다. 실행파일을 실행하면 Visual Studio Installer가 실행된다. | 4. Jupyter Notebook 커널을 설정한다. . 고민사항: . 가상환경은 생겼는데 커널을 선택할 때는 왜 가상환경이 안 보일까? | . 최소 ipykernel 또는 jupyter 패키지가 설치되어야 한다. | 터미널에서 가상환경을 활성화한다. | 다음 명령을 실행하여 커널을 추가한다. ipython kernel install --user --name=.venv --display-name (선택 창에서 보일 이름) | VSCode를 끄고 다시 켠다. | +)추가사항: Microsoft C++ Build Tools 설치 . 고민사항: 패키지 중에서는 Microsoft Visual C++ 14.0 이상을 요구하는 경우가 있다. 설치를 시도하면 다음 에러를 출력한다. . error: Microsoft Visual C++ 14.0 is required. Get it with “Microsoft Visual C++ Build Tools”: https://visualstudio.microsoft.com/downloads/ . 최근 Microsoft의 Build Tools설치 방법은 Installer를 설치하고 인터넷에서 다운로드 받아 설치하는 것을 기본으로 한다. 즉 폐쇄망에서 설치하려면 다른 방법이 필요하다. . 네트워크 환경에서 모든 Build Tools를 다운로드 받은 다음 폐쇄망으로 옮긴다. . MicroSoft 다운로드 웹페이지에서 빌드 도구(Build Tool)을 다운로드 받는다. | 빌드도구를 다운로드 받은 위치에서 명령창을 실행한다.: 다운로드 위치 파일 탐색기에서 주소창에 ‘cmd’입력 | 다음 명령어를 실행한다.: –add 옵션으로 어떤 build tool을 설치할지 지정할 수 있다. 만약 전체를 설치하려고 하면 엄청난 시간이 소요된다. . vs_buildtools__xxx.xxx.exe --layout (다운로드 받으려는 위치) --add Microsoft.VisualStudio.Component.VC.140 -includeOptional --add Microsoft.VisualStudio.Component.Windows10SDK.16299 --lang ko-KR 이 명령어로도 2시간 가량은 다운로드에 소요된다. | 위 명령어에 예를 들어 c: vslayout라고 입력했다면 vslayout폴더에 모든 내용이 다운로드 된다. 이 내용을 폐쇄망으로 옮긴다.(이 예시로는 대략 20GB정도 필요) | 폴더 내부에 vs_buildtools__xxx.xx.exe 실행파일을 실행한다. | Installer가 실행되고, 설치 가능한 항목이 자동으로 지정되어 있다. 그대로 설치한다. | 설치 완료하면 다시 Python 패키지를 설치한다. | 추가 고민 사항 . https://levelup.gitconnected.com/install-multiple-python-versions-on-windows-10-15a8685ec99d 주피터노트북 가상환경? . Reference . https://levelup.gitconnected.com/install-multiple-python-versions-on-windows-10-15a8685ec99d 여러 버전의 파이썬을 설치하는 것, 상세한 설치방법과 설치파일 복사하는 방법, 가상환경 생성 방법 설명 https://code.visualstudio.com/docs/python/python-tutorial#_install-and-use-packages VSCode에서 터미널로 가상환경을 생성하고 설치 권한을 조정하는 방법 https://korea1782.tistory.com/5 requirements.txt를 통한 빠른 패키지 설치 https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=c_ist82&amp;logNo=220788764088 패키지 설치 안내 https://srinivas1996kumar.medium.com/adding-custom-kernels-to-a-jupyter-notebook-in-visual-studio-53e4d595208c Jupyter Notebook에 커널 연결하기 https://pivox.tistory.com/35 C++ Build Tool 설치 https://velog.io/@flasharrow/pip-install-%EC%97%90%EB%9F%AC-Microsoft-Visual-C-14.0-is-required.-%ED%95%B4%EA%B2%B0 Microsoft C++ Build Tools 내부망에 설치(pyobdc 패키지 설치를 위해) .",
            "url": "https://floatingmanta.github.io/DAblog/markdown/2022/04/16/Venv-in-offline.html",
            "relUrl": "/markdown/2022/04/16/Venv-in-offline.html",
            "date": " • Apr 16, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://floatingmanta.github.io/DAblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://floatingmanta.github.io/DAblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://floatingmanta.github.io/DAblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://floatingmanta.github.io/DAblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}